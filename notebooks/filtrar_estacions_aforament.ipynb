{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from config.config import OBSERVACIONS_FILTRAT_DIR, OBSERVACIONS_DIR, ESTACIONS_DIR\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if path exists, delete it\n",
    "try:\n",
    "    shutil.rmtree(OBSERVACIONS_FILTRAT_DIR)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "OBSERVACIONS_FILTRAT_DIR.mkdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "De totes les estacions d'aforament, les que definim a continuació són les que en gran part tenen dades que semblen correctes.\n",
    "La resta, les descartem.\n",
    "Definit per Vicenç i Laia\n",
    "\"\"\"\n",
    "\n",
    "besos  = [19,20,30,35,38,39,40,50,51,59,62]\n",
    "fluvia = [18,42,69]\n",
    "llobregat = [1,3,4,7,9,11,12,17,23,24,25,26,29,31,41,45,46,49,54,57,58,71,72]\n",
    "muga = [5,8,36,43,44,55,61]\n",
    "sud = [13,16,37,66,70]\n",
    "ter = [21,22,28,33,34,47,48,52,53,60,65,67,68,73]\n",
    "\n",
    "estacions_incloses = set(besos + fluvia + llobregat + muga + sud + ter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min date: 2001-01-01\n",
      "Max date: 2021-02-16\n"
     ]
    }
   ],
   "source": [
    "#Min and max date in all the datasets in observacions_dir\n",
    "min_date = min(map(lambda path: pd.read_csv(path)[\"Date\"].min(), OBSERVACIONS_DIR.glob(\"*.csv\")))\n",
    "max_date = max(map(lambda path: pd.read_csv(path)[\"Date\"].max(), OBSERVACIONS_DIR.glob(\"*.csv\")))\n",
    "\n",
    "print(f\"Min date: {min_date}\")\n",
    "print(f\"Max date: {max_date}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Copy all files from observations to observations_filtrat\n",
    "for file in OBSERVACIONS_DIR.glob('*.csv'):\n",
    "\n",
    "    df = pd.read_csv(file)\n",
    "    \n",
    "    #Numero d'estacio\n",
    "    name_file = file.name\n",
    "    estacio = int(name_file.replace('.csv', '').replace('a', ''))\n",
    "\n",
    "    if estacio not in estacions_incloses:\n",
    "        continue\n",
    "\n",
    "    #date column to datetime\n",
    "    df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "    #Besòs\n",
    "    if estacio == 19:\n",
    "        df = df[(df['Date'] <= '2004-04-15') | (df['Date'] >= '2006-04-19')]\n",
    "\n",
    "    #Llobregat\n",
    "    elif estacio == 4:\n",
    "        df = df[(df['Date'] >= '2016-01-01')]\n",
    "    elif estacio == 12:\n",
    "        df = df[(df['Date'] <= '2012-08-19') | (df['Date'] >= '2015-01-01')]\n",
    "    elif estacio == 46:\n",
    "        df = df[((df['Date'] <= '2015-12-01') | (df['Date'] >= '2016-01-01')) & ((df['Date'] <= '2017-03-30') | (df['Date'] >= '2017-04-12'))]\n",
    "    \n",
    "    #Muga\n",
    "    elif estacio == 36:\n",
    "        df = df[(df['Date'] <= '2009-08-09') | (df['Date'] >= '2009-08-18')]\n",
    "    \n",
    "    #Ter\n",
    "    elif estacio == 48:\n",
    "        df = df[((df['Date'] <= '2006-01-22') | (df['Date'] >= '2008-02-27')) & (df['Date'] <= '2018-11-30')]\n",
    "    elif estacio == 60:\n",
    "        df = df[(df['Date'] <= '2015-12-31') | (df['Date'] >= '2019-10-22')]\n",
    "    elif estacio == 65:\n",
    "        df = df[((df['Date'] <= '2017-05-15') | (df['Date'] >= '2017-07-05')) & ((df['Date'] <= '2018-11-30') | (df['Date'] >= '2019-07-01'))]\n",
    "    elif estacio == 73:\n",
    "        df = df[df['Date'] != '2020-09-30']\n",
    "\n",
    "\n",
    "    \n",
    "    # create a new DataFrame with all dates between min_date and max_date\n",
    "    all_dates = pd.DataFrame({'Date': pd.date_range(start=pd.to_datetime(min_date), end=pd.to_datetime(max_date))})\n",
    "\n",
    "    # merge the two DataFrames using a left join\n",
    "    merged_df = pd.merge(all_dates, df, on='Date', how='left')\n",
    "\n",
    "    # replace missing flow values with NaN\n",
    "    merged_df['Flow'] = merged_df['Flow'].fillna(np.nan)\n",
    "    \n",
    "\n",
    "    merged_df.to_csv(Path(OBSERVACIONS_FILTRAT_DIR, name_file), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a9fa21406ecdfdb876493ce8c99362f54a867499c2f065970c4b152cdbf83136"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
